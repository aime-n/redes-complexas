{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32cd5d6a-4828-450c-bac5-62390af341f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from networkx import read_edgelist, set_node_attributes\n",
    "from pandas import read_csv, Series\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9232b5f0-a18e-473e-a4d5-69c15fef0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataSet = namedtuple(\n",
    "    'DataSet',\n",
    "    field_names=['X_train', 'y_train', 'X_test', 'y_test', 'network']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885f5a7f-3f50-4da9-9e53-2744f9fe1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_karate_club():\n",
    "    network = read_edgelist(\n",
    "        'karate.edgelist',\n",
    "        nodetype=int)\n",
    "\n",
    "    attributes = read_csv(\n",
    "        'karate.attributes.csv',\n",
    "        index_col=['node'])\n",
    "\n",
    "    for attribute in attributes.columns.values:\n",
    "        set_node_attributes(\n",
    "            network,\n",
    "            values=Series(\n",
    "                attributes[attribute],\n",
    "                index=attributes.index).to_dict(),\n",
    "            name=attribute\n",
    "        )\n",
    "\n",
    "    X_train, y_train = map(array, zip(*[\n",
    "        ([node], data['role'] == 'Administrator')\n",
    "        for node, data in network.nodes(data=True)\n",
    "        if data['role'] in {'Administrator', 'Instructor'}\n",
    "    ]))\n",
    "    X_test, y_test = map(array, zip(*[\n",
    "        ([node], data['community'] == 'Administrator')\n",
    "        for node, data in network.nodes(data=True)\n",
    "        if data['role'] == 'Member'\n",
    "    ]))\n",
    "    \n",
    "    return DataSet(\n",
    "        X_train, y_train,\n",
    "        X_test, y_test,\n",
    "        network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9035f68e-0f98-4b2f-b5ce-4a777039d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx import to_numpy_matrix, degree_centrality, betweenness_centrality, shortest_path_length\n",
    "import mxnet.ndarray as nd\n",
    "\n",
    "zkc = load_karate_club()\n",
    "\n",
    "A = to_numpy_matrix(zkc.network)\n",
    "A = nd.array(A)\n",
    "\n",
    "X_train = zkc.X_train.flatten()\n",
    "y_train = zkc.y_train\n",
    "X_test = zkc.X_test.flatten()\n",
    "y_test = zkc.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5370e27-6780-4536-b291-1092ded782bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import HybridBlock\n",
    "from mxnet.gluon.nn import Activation\n",
    "import mxnet.ndarray as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a0ed019-d6fe-460a-b0bb-f2c5931817c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralRule(HybridBlock):\n",
    "    def __init__(self,\n",
    "                 A, in_units, out_units,\n",
    "                 activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        I = nd.eye(*A.shape)\n",
    "        A_hat = A.copy() + I\n",
    "        D = nd.sum(A_hat, axis=0)\n",
    "        D_inv = D**-0.5\n",
    "        D_inv = nd.diag(D_inv)\n",
    "        A_hat = D_inv * A_hat * D_inv\n",
    "        \n",
    "        self.in_units, self.out_units = in_units, out_units\n",
    "        \n",
    "        with self.name_scope():\n",
    "            self.A_hat = self.params.get_constant('A_hat', A_hat)\n",
    "            self.W = self.params.get(\n",
    "                'W', shape=(self.in_units, self.out_units)\n",
    "            )\n",
    "            if activation == 'ident':\n",
    "                self.activation = lambda X: X\n",
    "            else:\n",
    "                self.activation = Activation(activation)\n",
    "    def hybrid_forward(self, F, X, A_hat, W):\n",
    "        aggregate = F.dot(A_hat, X)\n",
    "        propagate = self.activation(\n",
    "            F.dot(aggregate, W))\n",
    "        return propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1704925-7f9d-4ec7-8788-0ab7978f7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor(HybridBlock):\n",
    "    def __init__(self, in_units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.w = self.params.get(\n",
    "                'w', shape=(1, in_units)\n",
    "            )\n",
    "\n",
    "            self.b = self.params.get(\n",
    "                'b', shape=(1, 1)\n",
    "            )\n",
    "\n",
    "    def hybrid_forward(self, F, X, w, b):\n",
    "        # Change shape of b to comply with MXnet addition API\n",
    "        b = F.broadcast_axis(b, axis=(0,1), size=(34, 1))\n",
    "        y = F.dot(X, w, transpose_b=True) + b\n",
    "\n",
    "        return F.sigmoid(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95d854ec-1b9f-4815-9285-2767da42abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon.nn import HybridSequential, Activation\n",
    "from mxnet.ndarray import array\n",
    "from mxnet.initializer import One, Uniform, Xavier\n",
    "from mxnet.gluon.loss import SigmoidBinaryCrossEntropyLoss\n",
    "\n",
    "def build_features(A, X):\n",
    "    hidden_layer_specs = [(4, 'tanh'), (2, 'tanh')] # Format: (units in layer, activation function)\n",
    "    in_units = in_units=X.shape[1]\n",
    "  \n",
    "    features = HybridSequential()\n",
    "    with features.name_scope():\n",
    "        for i, (layer_size, activation_func) in enumerate(hidden_layer_specs):\n",
    "            layer = SpectralRule(\n",
    "                A, in_units=in_units, out_units=layer_size, \n",
    "                activation=activation_func)\n",
    "            features.add(layer)\n",
    "\n",
    "            in_units = layer_size\n",
    "    return features, in_units\n",
    "\n",
    "def build_model(A, X):\n",
    "    model = HybridSequential()\n",
    "    hidden_layer_specs = [(4, 'tanh'), (2, 'tanh')]\n",
    "    in_units = in_units=X.shape[1]\n",
    "\n",
    "    with model.name_scope():\n",
    "        features, out_units = build_features(A, X)\n",
    "        model.add(features)\n",
    "\n",
    "        classifier = LogisticRegressor(out_units)\n",
    "        model.add(classifier)\n",
    "\n",
    "    model.hybridize()\n",
    "    model.initialize(Uniform(1))\n",
    "\n",
    "    return model, features\n",
    "\n",
    "from mxnet.gluon.nn import HybridSequential, Activation\n",
    "from mxnet.ndarray import array\n",
    "from mxnet.initializer import One, Uniform, Xavier\n",
    "from mxnet.gluon.loss import SigmoidBinaryCrossEntropyLoss\n",
    "\n",
    "def build_features(A, X):\n",
    "    hidden_layer_specs = [(4, 'tanh'), (2, 'tanh')] # Format: (units in layer, activation function)\n",
    "    in_units = in_units=X.shape[1]\n",
    "  \n",
    "    features = HybridSequential()\n",
    "    with features.name_scope():\n",
    "        for i, (layer_size, activation_func) in enumerate(hidden_layer_specs):\n",
    "            layer = SpectralRule(\n",
    "                A, in_units=in_units, out_units=layer_size, \n",
    "                activation=activation_func)\n",
    "            features.add(layer)\n",
    "\n",
    "            in_units = layer_size\n",
    "    return features, in_units\n",
    "\n",
    "def build_model(A, X):\n",
    "    model = HybridSequential()\n",
    "    hidden_layer_specs = [(4, 'tanh'), (2, 'tanh')]\n",
    "    in_units = in_units=X.shape[1]\n",
    "\n",
    "    with model.name_scope():\n",
    "        features, out_units = build_features(A, X)\n",
    "        model.add(features)\n",
    "\n",
    "        classifier = LogisticRegressor(out_units)\n",
    "        model.add(classifier)\n",
    "\n",
    "    model.hybridize()\n",
    "    model.initialize(Uniform(1))\n",
    "\n",
    "    return model, features\n",
    "\n",
    "from mxnet.gluon.nn import HybridSequential, Activation\n",
    "from mxnet.ndarray import array\n",
    "from mxnet.initializer import One, Uniform, Xavier\n",
    "from mxnet.gluon.loss import SigmoidBinaryCrossEntropyLoss\n",
    "\n",
    "def build_features(A, X):\n",
    "    hidden_layer_specs = [(4, 'tanh'), (2, 'tanh')] # Format: (units in layer, activation function)\n",
    "    in_units = in_units=X.shape[1]\n",
    "  \n",
    "    features = HybridSequential()\n",
    "    with features.name_scope():\n",
    "        for i, (layer_size, activation_func) in enumerate(hidden_layer_specs):\n",
    "            layer = SpectralRule(\n",
    "                A, in_units=in_units, out_units=layer_size, \n",
    "                activation=activation_func)\n",
    "            features.add(layer)\n",
    "\n",
    "            in_units = layer_size\n",
    "    return features, in_units\n",
    "\n",
    "def build_model(A, X):\n",
    "    model = HybridSequential()\n",
    "    hidden_layer_specs = [(4, 'tanh'), (2, 'tanh')]\n",
    "    in_units = in_units=X.shape[1]\n",
    "\n",
    "    with model.name_scope():\n",
    "        features, out_units = build_features(A, X)\n",
    "        model.add(features)\n",
    "\n",
    "        classifier = LogisticRegressor(out_units)\n",
    "        model.add(classifier)\n",
    "\n",
    "    model.hybridize()\n",
    "    model.initialize(Uniform(1))\n",
    "\n",
    "    return model, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5566e32c-7be9-4057-a9cd-cf49c0a7bc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.5106775 ]\n",
       " [0.5095114 ]\n",
       " [0.51096225]\n",
       " [0.51542187]\n",
       " [0.523025  ]\n",
       " [0.512526  ]\n",
       " [0.511652  ]\n",
       " [0.50208426]\n",
       " [0.5050116 ]\n",
       " [0.51883554]\n",
       " [0.5406651 ]\n",
       " [0.49158806]\n",
       " [0.5110878 ]\n",
       " [0.4936631 ]\n",
       " [0.5026252 ]\n",
       " [0.48504698]\n",
       " [0.5104648 ]\n",
       " [0.51193994]\n",
       " [0.5220448 ]\n",
       " [0.50951165]\n",
       " [0.50140274]\n",
       " [0.5098576 ]\n",
       " [0.53033787]\n",
       " [0.51043373]\n",
       " [0.50124794]\n",
       " [0.52045095]\n",
       " [0.50941336]\n",
       " [0.49507195]\n",
       " [0.5021959 ]\n",
       " [0.5068235 ]\n",
       " [0.5085803 ]\n",
       " [0.51637703]\n",
       " [0.50986254]\n",
       " [0.5153003 ]]\n",
       "<NDArray 34x1 @cpu(0)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = I = nd.eye(*A.shape)\n",
    "model_1, features_1 = build_model(A, X_1)\n",
    "model_1(X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eac664a-7f1b-4409-94b3-2984375fdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = nd.zeros((A.shape[0], 2))\n",
    "node_distance_instructor = shortest_path_length(zkc.network, target=33)\n",
    "node_distance_administrator = shortest_path_length(zkc.network, target=0)\n",
    "\n",
    "for node in zkc.network.nodes():\n",
    "    X_2[node][0] = node_distance_administrator[node]\n",
    "    X_2[node][1] = node_distance_instructor[node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40a37ea7-1ed1-4c6a-bdca-00d5362a65e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.30647328]\n",
       " [0.30417648]\n",
       " [0.3039074 ]\n",
       " [0.3026266 ]\n",
       " [0.2761228 ]\n",
       " [0.2871463 ]\n",
       " [0.2901096 ]\n",
       " [0.28990412]\n",
       " [0.29719502]\n",
       " [0.29228204]\n",
       " [0.23410328]\n",
       " [0.27259356]\n",
       " [0.29702023]\n",
       " [0.28627372]\n",
       " [0.28598285]\n",
       " [0.2841425 ]\n",
       " [0.29827604]\n",
       " [0.29667538]\n",
       " [0.27046144]\n",
       " [0.30377817]\n",
       " [0.28733426]\n",
       " [0.3051519 ]\n",
       " [0.28729206]\n",
       " [0.30674195]\n",
       " [0.278353  ]\n",
       " [0.28005856]\n",
       " [0.27564093]\n",
       " [0.29431537]\n",
       " [0.27612218]\n",
       " [0.2979673 ]\n",
       " [0.29401767]\n",
       " [0.29911888]\n",
       " [0.2852555 ]\n",
       " [0.29837865]]\n",
       "<NDArray 34x1 @cpu(0)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = nd.concat(X_1, X_2)\n",
    "model_2, features_2 = build_model(A, X_2)\n",
    "model_2(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f0d9e3b-8d9c-4fad-bfc0-8dfc14fae0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time\n",
    "from mxnet import autograd\n",
    "from mxnet.gluon import Trainer\n",
    "from mxnet.ndarray import sum as ndsum\n",
    "import numpy as np\n",
    "\n",
    "def train(model, features, X, X_train, y_train, epochs):\n",
    "    cross_entropy = SigmoidBinaryCrossEntropyLoss(from_sigmoid=True)\n",
    "    trainer = Trainer(model.collect_params(), 'sgd', {'learning_rate': 0.001, 'momentum': 1})\n",
    "\n",
    "    feature_representations = [features(X).asnumpy()]\n",
    "\n",
    "    for e in range(1, epochs + 1):\n",
    "        cum_loss = 0\n",
    "        cum_preds = []\n",
    "\n",
    "        for i, x in enumerate(X_train):\n",
    "            y = array(y_train)[i]\n",
    "            with autograd.record():\n",
    "                preds = model(X)[x]\n",
    "                loss = cross_entropy(preds, y)\n",
    "            loss.backward()\n",
    "            trainer.step(1)\n",
    "\n",
    "            cum_loss += loss.asscalar()\n",
    "            cum_preds += [preds.asscalar()]\n",
    "\n",
    "        feature_representations.append(features(X).asnumpy())\n",
    "            \n",
    "        if (e % (epochs//10)) == 0:\n",
    "            print(f\"Epoch {e}/{epochs} -- Loss: {cum_loss: .4f}\")\n",
    "            print(cum_preds)\n",
    "    return feature_representations\n",
    "\n",
    "def predict(model, X, nodes):\n",
    "    preds = model(X)[nodes].asnumpy().flatten()\n",
    "    return np.where(preds >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0bfd8d8-19d0-459f-b31a-afa902e6dc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/5000 -- Loss:  0.0001\n",
      "[0.9999902, 4.623498e-05]\n",
      "Epoch 1000/5000 -- Loss:  0.0000\n",
      "[1.0, 8.9681595e-10]\n",
      "Epoch 1500/5000 -- Loss:  0.0000\n",
      "[1.0, 1.752139e-14]\n",
      "Epoch 2000/5000 -- Loss:  0.0000\n",
      "[1.0, 3.4294267e-19]\n",
      "Epoch 2500/5000 -- Loss:  0.0000\n",
      "[1.0, 6.712246e-24]\n",
      "Epoch 3000/5000 -- Loss:  0.0000\n",
      "[1.0, 1.3137748e-28]\n",
      "Epoch 3500/5000 -- Loss:  0.0000\n",
      "[1.0, 2.5714253e-33]\n",
      "Epoch 4000/5000 -- Loss:  0.0000\n",
      "[1.0, 5.0596415e-38]\n",
      "Epoch 4500/5000 -- Loss:  0.0000\n",
      "[1.0, 0.0]\n",
      "Epoch 5000/5000 -- Loss:  0.0000\n",
      "[1.0, 0.0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.50      0.55        16\n",
      "        True       0.58      0.69      0.63        16\n",
      "\n",
      "    accuracy                           0.59        32\n",
      "   macro avg       0.60      0.59      0.59        32\n",
      "weighted avg       0.60      0.59      0.59        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "feature_representations_1 = train(model_1, features_1, X_1, X_train, y_train, epochs=5000)\n",
    "y_pred_1 = predict(model_1, X_1, X_test)\n",
    "print(classification_report(y_test, y_pred_1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3a8c2bb-256e-41bf-be5b-b7f8265ee576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/250 -- Loss:  1.4545\n",
      "[0.35830984, 0.34828502]\n",
      "Epoch 50/250 -- Loss:  1.3412\n",
      "[0.5004881, 0.47743362]\n",
      "Epoch 75/250 -- Loss:  1.3454\n",
      "[0.6495548, 0.59905267]\n",
      "Epoch 100/250 -- Loss:  1.2656\n",
      "[0.7196256, 0.608015]\n",
      "Epoch 125/250 -- Loss:  0.9153\n",
      "[0.7071581, 0.43381798]\n",
      "Epoch 150/250 -- Loss:  0.6043\n",
      "[0.65691596, 0.16817342]\n",
      "Epoch 175/250 -- Loss:  0.4856\n",
      "[0.6474464, 0.0495758]\n",
      "Epoch 200/250 -- Loss:  0.3495\n",
      "[0.7186822, 0.018995365]\n",
      "Epoch 225/250 -- Loss:  0.1905\n",
      "[0.8350884, 0.010186707]\n",
      "Epoch 250/250 -- Loss:  0.0813\n",
      "[0.92820424, 0.006742709]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.94      0.68        16\n",
      "        True       0.75      0.19      0.30        16\n",
      "\n",
      "    accuracy                           0.56        32\n",
      "   macro avg       0.64      0.56      0.49        32\n",
      "weighted avg       0.64      0.56      0.49        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_representations_2= train(model_2, features_2, X_2, X_train, y_train, epochs=250)\n",
    "y_pred_2 = predict(model_2, X_2, X_test)\n",
    "print(classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb177e7-f902-4795-b485-d5906e8c3565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
